{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097, 477)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv',  delimiter = ',',  skip_header = 1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Are movies that are more popular (operationalized as having more ratings) rated higher than movies that are less popular? \\[Hint: You can do a median-split of popularity to determine high vs. low popularity movies\\]\n",
    "\n",
    "Test: Mann Whitney U test\n",
    "\n",
    "- Reason for choosing this test\n",
    "\n",
    " Firstly, this movie rating data cannot be reduced to sample means considering the characteristics of movie rating score. For exmaple, difference in rating 3 and 4, and difference in rating 4 and 5 is not the same though numerically the difference is the same(1 point). This is because to be closer to 5 requires much better quality than closer to 4, because 5 is the perfect score.\n",
    " Next, the data is not categorical and it can be ordered from 0 to 4. In addition, there are some datas which is decimals such as 3.5 and 1.5, which means the data is continuous and cannot be separated into categories.\n",
    " Furthermore, the movies are divided into 2 groups which are high popularity group and low popularity group. Finally, we will compare median value of the movie ratings, so Mann Whitney U test is proper test method.\n",
    "\n",
    "\n",
    "- How to do the test \\\n",
    "1) Calculate Median \\\n",
    "2) Separate into movie ratings into low popularity group and high popularity group \\\n",
    "3) Calculate median for each movie (for the NaN value, discard it.) \\\n",
    "4) Run Mann Whitney U test with medians of low popularity group and high popularity group\n",
    "   (Since we are testing \"rated higher\", use 'greater' option(one-sided test)).\n",
    "\n",
    "\n",
    "- Test Result\n",
    "\n",
    " Ha: movies that are more popular(operationalized as having more ratings) rated higher than movies that are less popular \\\n",
    " H0: movies that are more popular rated less than or equal to movies that are less popular\n",
    "\n",
    " Based on the test, p-value is 9.929258851707232e-35 which is smaller than 0.005\n",
    " Accordingly, reject the null hypothesis(H0: movies that are more popular rated less than or equal to movies that are less popular), and movies that are more popular(operationalized as having more ratings) rated higher than movies that are less popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median:  197.5\n",
      "9.929258851707232e-35\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "# Calculate median\n",
    "transposed_data = data.T # transpose and make one row for each movie\n",
    "\n",
    "ratings = transposed_data[:400]\n",
    "colNum = data.shape\n",
    "\n",
    "popularity = []\n",
    "for movie in ratings:\n",
    "    popularity.append(np.isfinite(movie).sum())\n",
    "\n",
    "median = np.median(np.array(popularity))\n",
    "print('median: ', median)\n",
    "\n",
    "# separate into low group and high group\n",
    "low = []\n",
    "high = []\n",
    "for movie in ratings:\n",
    "    if np.isfinite(movie).sum() < median:\n",
    "        low.append(movie)\n",
    "    else:\n",
    "        high.append(movie)\n",
    "\n",
    "\n",
    "low_medians = []\n",
    "for movie in low:\n",
    "    low_medians.append(np.nanmedian(movie))\n",
    "\n",
    "high_medians = []\n",
    "for movie in high:\n",
    "    high_medians.append(np.nanmedian(movie))\n",
    "    \n",
    "u1,p1 = stats.mannwhitneyu(high_medians, low_medians, alternative = 'greater')\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Are movies that are newer rated differently than movies that are older? \\[Hint: Do a median split of year of release to contrast movies in terms of whether they are old or new\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "median:  1999.0\n",
      "[1960.0, 1966.0, 1966.0, 1966.0, 1967.0, 1967.0, 1967.0, 1968.0, 1968.0, 1968.0, 1968.0, 1968.0, 1969.0, 1969.0, 1969.0, 1970.0, 1970.0, 1970.0, 1971.0, 1971.0, 1971.0, 1972.0, 1972.0, 1972.0, 1973.0, 1973.0, 1973.0, 1973.0, 1974.0, 1974.0, 1974.0, 1974.0, 1975.0, 1975.0, 1975.0, 1976.0, 1976.0, 1976.0, 1976.0, 1976.0, 1977.0, 1977.0, 1977.0, 1977.0, 1978.0, 1978.0, 1978.0, 1978.0, 1979.0, 1979.0, 1979.0, 1979.0, 1980.0, 1980.0, 1980.0, 1980.0, 1981.0, 1981.0, 1981.0, 1981.0, 1982.0, 1982.0, 1982.0, 1982.0, 1982.0, 1983.0, 1983.0, 1983.0, 1984.0, 1984.0, 1984.0, 1984.0, 1985.0, 1985.0, 1985.0, 1985.0, 1986.0, 1986.0, 1986.0, 1986.0, 1986.0, 1987.0, 1987.0, 1987.0, 1987.0, 1987.0, 1987.0, 1988.0, 1988.0, 1988.0, 1988.0, 1988.0, 1988.0, 1988.0, 1989.0, 1989.0, 1989.0, 1989.0, 1989.0, 1990.0, 1990.0, 1990.0, 1990.0, 1990.0, 1990.0, 1990.0, 1991.0, 1991.0, 1991.0, 1991.0, 1991.0, 1991.0, 1992.0, 1992.0, 1992.0, 1992.0, 1992.0, 1992.0, 1993.0, 1993.0, 1993.0, 1993.0, 1993.0, 1993.0, 1993.0, 1993.0, 1994.0, 1994.0, 1994.0, 1994.0, 1994.0, 1994.0, 1994.0, 1994.0, 1994.0, 1994.0, 1994.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1995.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1996.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1997.0, 1998.0, 1998.0, 1998.0, 1998.0, 1998.0, 1998.0, 1998.0, 1998.0, 1998.0, 1998.0, 1998.0, 1998.0, 1998.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 1999.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2001.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2002.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2003.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2005.0, 2005.0, 2005.0, 2005.0, 2006.0, 2006.0, 2006.0, 2007.0, 2007.0, 2007.0, 2007.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2009.0, 2009.0, 2009.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2011.0, 2011.0, 2011.0, 2011.0, 2012.0, 2012.0, 2012.0, 2012.0, 2013.0, 2013.0, 2013.0, 2013.0, 2014.0, 2014.0, 2014.0, 2014.0, 2015.0, 2015.0, 2015.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0]\n",
      "(1097, 400)\n",
      "174 225\n",
      "0.21113405794975193\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# data_with_name = np.genfromtxt('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', delimiter = ',', names = True)\n",
    "# movie_titles = data_with_name.dtype.names[:400]\n",
    "# movie_titles\n",
    "\n",
    "#find median\n",
    "data_with_name = pd.read_csv('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', skipinitialspace = True)\n",
    "titles = data_with_name.columns\n",
    "\n",
    "years = []\n",
    "titles = titles[:400]\n",
    "print(len(titles))\n",
    "for title in titles:\n",
    "    if title.rfind('(') == -1:\n",
    "        continue\n",
    "    \n",
    "    #print(title)\n",
    "    start = title.rfind('(')\n",
    "    end = title.rfind(')')\n",
    "    year_str = title[start+1:end]\n",
    "    year_str = year_str.strip()\n",
    "    years.append(float(year_str))\n",
    "    #year = int(float(year_str))\n",
    "\n",
    "median = np.median(np.array(years))\n",
    "print('median: ', median)\n",
    "\n",
    "years.sort()\n",
    "print(years)\n",
    "\n",
    "#data_with_name = data_with_name[:400]\n",
    "data_with_name = data_with_name.iloc[:, 0:400]\n",
    "print(data_with_name.shape)\n",
    "\n",
    "\n",
    "low_medians = []\n",
    "high_medians = []\n",
    "low = 0\n",
    "high = 0\n",
    "for title in data_with_name.columns:\n",
    "    if title.rfind('(') == -1:\n",
    "        continue\n",
    "        \n",
    "    start = title.rfind('(')\n",
    "    end = title.rfind(')')\n",
    "    year_str = title[start+1:end]\n",
    "    year_str = year_str.strip()\n",
    "    year = int(year_str)\n",
    "    \n",
    "    if year > median:\n",
    "        rating = data_with_name[title].to_numpy()\n",
    "        high_medians.append(np.nanmedian(rating))\n",
    "        low += 1\n",
    "#         print(year)\n",
    "#         print(type(data_with_name[title].to_numpy())\n",
    "    else:\n",
    "        rating = data_with_name[title].to_numpy()\n",
    "        low_medians.append(np.nanmedian(rating))\n",
    "        high += 1\n",
    "    \n",
    "print(low, high)\n",
    "u1,p1 = stats.mannwhitneyu(low_medians, high_medians)\n",
    "print(p1)\n",
    "\n",
    "\n",
    "\n",
    "# # find median\n",
    "# data_with_name = np.genfromtxt('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', delimiter = ',', names = True)\n",
    "\n",
    "# #data_with_name = np.genfromtxt('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', delimiter = ',')\n",
    "# print(data_with_name.shape)\n",
    "# print(data_with_name)\n",
    "# movie_titles = data_with_name.dtype.names[:400]\n",
    "\n",
    "# years = []\n",
    "# for title in movie_titles:\n",
    "#     start = title.rfind('_')\n",
    "#     year = title[start+1:]\n",
    "#     #if year.isnumeric():\n",
    "#         #print(int(year))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Is enjoyment of 'Shrek(2001)' gendered, i.e. do male and female viewers rate it differently? \n",
    "\n",
    "Test: Mann Whitney U test\n",
    "\n",
    "- Reason for choosing this test\n",
    "\n",
    " Firstly, this movie rating data cannot be reduced to sample means considering the characteristics of movie rating score. For exmaple, difference in rating 3 and 4, and difference in rating 4 and 5 is not the same though numerically the difference is the same(1 point). This is because to be closer to 5 requires much better quality than closer to 4, because 5 is the perfect score.\n",
    " Next, the data is not categorical and it can be ordered from 0 to 4. In addition, there are some datas which is decimals such as 3.5 and 1.5, which means the data is continuous and cannot be separated into categories.\n",
    " Furthermore, the movies should be divided into 2 groups which are male group and female group. Finally, we will compare median value of the movie ratings, so Mann Whitney U test is proper test method.\n",
    "\n",
    "\n",
    "- How to do the test \\\n",
    "1) For the 'Shrek(2001)' movie, separate the movie rating into male group and female group \\\n",
    "   (for the NaN value, discard it.) \\\n",
    "2) Run Mann Whitney U test with ratings for 'Shrek(2001)' from male group and female group\\\n",
    "   (Since we are testing \"rate differently\" which means the same or not, use 'two-sided' option).\n",
    "\n",
    "\n",
    "- Test Result\n",
    "\n",
    " Ha: Male and female viewers rate 'Shrek(2001)' differently \\\n",
    " H0: Male and female viewres rate 'Shrek(2001)' same\n",
    " \n",
    " Based on the test, p-value is 0.050536625925559006 which is larger than significance level(0.005)\n",
    " Accordingly, accept Null Hypothesis H0: Male and female viewres rate 'Shrek(2001)' same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050536625925559006\n"
     ]
    }
   ],
   "source": [
    "# 3 TODO check self-rated?\n",
    "data = pd.read_csv('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', skipinitialspace = True)\n",
    "shrek = data['Shrek (2001)'].to_numpy()\n",
    "gender = data['Gender identity (1 = female; 2 = male; 3 = self-described)'].to_numpy()\n",
    "\n",
    "female_rates = []\n",
    "male_rates = []\n",
    "for i in range(0, len(gender)):\n",
    "    if gender[i] == 1 and not np.isnan(shrek[i]):\n",
    "        female_rates.append(shrek[i])\n",
    "    elif gender[i] == 2 and not np.isnan(shrek[i]):\n",
    "        male_rates.append(shrek[i])\n",
    "        \n",
    "u1,p1 = stats.mannwhitneyu(female_rates, male_rates) # alternative: two-sided\n",
    "print(p1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What proportion of movies are rated differently by male and female viewers?\n",
    "\n",
    "Test: Mann Whitney U test\n",
    "\n",
    "- Reason for choosing this test\n",
    "\n",
    " Firstly, this movie rating data cannot be reduced to sample means considering the characteristics of movie rating score. For exmaple, difference in rating 3 and 4, and difference in rating 4 and 5 is not the same though numerically the difference is the same(1 point). This is because to be closer to 5 requires much better quality than closer to 4, because 5 is the perfect score.\n",
    " Next, the data is not categorical and it can be ordered from 0 to 4. In addition, there are some datas which is decimals such as 3.5 and 1.5, which means the data is continuous and cannot be separated into categories.\n",
    " Furthermore, the movie ratings should be divided into 2 groups which are male group and female group. Finally, we will compare median value of the movie ratings, so Mann Whitney U test is proper test method.\n",
    "\n",
    "\n",
    "- How to do the test \\\n",
    "1) For each movie ratings, divide rates into male group and female group.\\\n",
    "   (for the NaN value, discard it.) \\\n",
    "2) Run Mann Whitney U test for each movie and get p-value \\\n",
    "    (Since we are testing \"rate differently\" which means the same or not, use 'two-sided' option). \\\n",
    "    Ha : movies are rated differently by male and female viewers \\\n",
    "    H0 : movies are rated same by male and female viewers \\\n",
    "3) If p-value is smaller than significance level(0.005), count that movie\n",
    "    -> Reject Null Hypothesis(H0 : movies are rated same by male and female viewers)\n",
    "4) get the ratio with count\n",
    "\n",
    "\n",
    "- Test Result : 0.125 \\\n",
    ": 50 movies out of 400 movies are rated differently by male and female viewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "data = pd.read_csv('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', skipinitialspace = True)\n",
    "titles = data_with_name.columns\n",
    "titles = titles[:400]\n",
    "gender = data['Gender identity (1 = female; 2 = male; 3 = self-described)'].to_numpy()\n",
    "\n",
    "count = 0\n",
    "for title in titles:\n",
    "    movie_rating = data[title]\n",
    "    \n",
    "    female_rates = []\n",
    "    male_rates = []\n",
    "    for i in range(0, len(gender)):\n",
    "        if gender[i] == 1 and not np.isnan(movie_rating[i]):\n",
    "            female_rates.append(movie_rating[i])\n",
    "        elif gender[i] == 2 and not np.isnan(movie_rating[i]):\n",
    "            male_rates.append(movie_rating[i])\n",
    "            \n",
    "    u1, p1 = stats.mannwhitneyu(female_rates, male_rates) # alternative: two-sided\n",
    "    \n",
    "    if p1 < 0.005:\n",
    "        count += 1\n",
    "\n",
    "print(count)\n",
    "count / 400\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Do people who are only children enjoy 'The Lion King(1994)' more than people with siblings?\n",
    "\n",
    "Test: Mann Whitney U test\n",
    "\n",
    "- Reason for choosing this test\n",
    "\n",
    " Firstly, this movie rating data cannot be reduced to sample means considering the characteristics of movie rating score. For exmaple, difference in rating 3 and 4, and difference in rating 4 and 5 is not the same though numerically the difference is the same(1 point). This is because to be closer to 5 requires much better quality than closer to 4, because 5 is the perfect score.\n",
    " Next, the data is not categorical and it can be ordered from 0 to 4. In addition, there are some datas which is decimals such as 3.5 and 1.5, which means the data is continuous and cannot be separated into categories.\n",
    " Furthermore, the movies should be divided into 2 groups which are only children group and people with siblings group. Finally, we will compare median value of the movie ratings, so Mann Whitney U test is proper test method.\n",
    "\n",
    "\n",
    "- How to do the test \\\n",
    "1) For the 'The Lion King(1994)' movie, separate the movie rating into only children group and people with siblings group (for the NaN value, discard it.) \\\n",
    "2) Run Mann Whitney U test with ratings for 'The Lion King(1994)' from only children group and people with siblings group\\\n",
    "(Since we are testing \"enjoy more than\", use 'greater' option(one-sided test)).\n",
    "\n",
    "\n",
    "\n",
    "- Test Result\n",
    "\n",
    " Ha: Only children viewers and viewers with siblings group enjoy 'The Lion King(1994)' more \\\n",
    " H0: Only children viewers and viewers with siblings group enjoy 'The Lion King(1994)' less\n",
    " \n",
    " Based on the test, p-value is 0.978419092554931 which is larger than significance level(0.005).\n",
    " Accordingly, accept Null Hypothesis(H0: Only children viewers and viewers with siblings group enjoy 'The Lion King(1994)' less.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978419092554931\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "data = pd.read_csv('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', skipinitialspace = True)\n",
    "lion_king = data['The Lion King (1994)'].to_numpy()\n",
    "relation = data['Are you an only child? (1: Yes; 0: No; -1: Did not respond)'].to_numpy()\n",
    "\n",
    "only_children = []\n",
    "siblings = []\n",
    "\n",
    "for i in range(0, len(gender)):\n",
    "    if relation[i] == 1 and not np.isnan(lion_king[i]):\n",
    "        only_children.append(lion_king[i])\n",
    "    elif relation[i] == 0 and not np.isnan(lion_king[i]):\n",
    "        siblings.append(lion_king[i])\n",
    "        \n",
    "u1,p1 = stats.mannwhitneyu(only_children, siblings, alternative = 'greater')\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What proportion of movies exhibit an \"only child effect\", i.e. are rated differently by viewers with siblings vs. those without?\n",
    "\n",
    "Test: Mann Whitney U test\n",
    "\n",
    "- Reason for choosing this test\n",
    "\n",
    " Firstly, this movie rating data cannot be reduced to sample means considering the characteristics of movie rating score. For exmaple, difference in rating 3 and 4, and difference in rating 4 and 5 is not the same though numerically the difference is the same(1 point). This is because to be closer to 5 requires much better quality than closer to 4, because 5 is the perfect score.\n",
    " Next, the data is not categorical and it can be ordered from 0 to 4. In addition, there are some datas which is decimals such as 3.5 and 1.5, which means the data is continuous and cannot be separated into categories.\n",
    " Furthermore, the movie ratings should be divided into 2 groups which are viewers with siblings group and viewers without siblings group. Finally, we will compare median value of the movie ratings, so Mann Whitney U test is proper test method.\n",
    "\n",
    "\n",
    "\n",
    "- How to do the test \\\n",
    "1) For each movie ratings, divide rates into 2 groups(viewers with siblings group and viewers without siblings group)\\\n",
    "   (for the NaN value, discard it.)\\\n",
    "2) Run Mann Whitney U test for each movie and get p-value \\\n",
    "(Since we are testing \"rate differently\" which means the same or not, use 'two-sided' option).\\\n",
    "    Ha : movies are rated differently by viewers with siblings group and viewers without siblings group \\\n",
    "    H0 : movies are rated same by viewers with siblings group and viewers without siblings group \\\n",
    "3) If p-value is smaller than significance level(0.005), count that movie\\\n",
    "    -> Reject Null Hypothesis(H0 : movies are rated same by viewers with siblings group and viewers without siblings group)\\\n",
    "4) get the ratio with count\n",
    "\n",
    "\n",
    "- Test Result : 0.0175 \\\n",
    ": 7 movies out of 400 movies are rated differently by viewers with siblings group and viewers without siblings group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0175"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6\n",
    "data = pd.read_csv('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', skipinitialspace = True)\n",
    "titles = data_with_name.columns\n",
    "titles = titles[:400]\n",
    "relation = data['Are you an only child? (1: Yes; 0: No; -1: Did not respond)'].to_numpy()\n",
    "\n",
    "count = 0\n",
    "for title in titles:\n",
    "    movie_rating = data[title]\n",
    "    \n",
    "    only_children = []\n",
    "    siblings = []\n",
    "    for i in range(0, len(relation)):\n",
    "        if relation[i] == 1 and not np.isnan(movie_rating[i]):\n",
    "            only_children.append(movie_rating[i])\n",
    "        elif relation[i] == 0 and not np.isnan(movie_rating[i]):\n",
    "            siblings.append(movie_rating[i])\n",
    "            \n",
    "    u1, p1 = stats.mannwhitneyu(siblings, only_children)\n",
    "    \n",
    "    #print(p1)\n",
    "    if p1 < 0.005:\n",
    "        count += 1\n",
    "\n",
    "print(count)\n",
    "count / 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Do people who like to watch movies socially enjoy 'The Wolf of Wall Street(2013)' more than those who prefer to watch them alone?\n",
    "\n",
    "Test: Mann Whitney U test\n",
    "\n",
    "- Reason for choosing this test\n",
    "\n",
    " Firstly, this movie rating data cannot be reduced to sample means considering the characteristics of movie rating score. For example, difference in rating 3 and 4, and difference in rating 4 and 5 is not the same though numerically the difference is the same(1 point). This is because to be closer to 5 requires much better quality than closer to 4, because 5 is the perfect score.\n",
    " Next, the data is not categorical and it can be ordered from 0 to 4. In addition, there are some datas which is decimals such as 3.5 and 1.5, which means the data is continuous and cannot be separated into categories.\n",
    " Furthermore, the movies are divided into 2 groups which are people who like to watch movies socially group and people prefer to watch movies alone group. Finally, we will compare median value of the movie ratings, so Mann Whitney U test is proper test method.\n",
    " \n",
    "\n",
    "- How to do the test \\\n",
    "1) For the 'The Wolf of Wall Street(2013)' movie, separate the movie rating into people who like to watch movies socially group and people prefer to watch movies alone group (for the NaN value, discard it.) \\\n",
    "2) Run Mann Whitney U test with ratings for 'The Wolf of Wall Street(2013)' from people who like to watch movies socially group and people prefer to watch movies alone group\\\n",
    "(Since we are testing \"enjoy more than\", use 'greater' option(one-sided test)).\n",
    "\n",
    "\n",
    "- Test Result\n",
    "\n",
    " Ha: People who like to watch movies socially enjoy 'The Wolf of Wall Street(2013)' more than those who prefer to watch them alone. \\\n",
    " H0: People who like to watch movies socially enjoy 'The Wolf of Wall Street(2013)' less than those who prefer to watch them alone.\n",
    "\n",
    " Based on the test, p-value is 0.9436657996253056 which is larger than significance level(0.005).\n",
    " Accordingly, accept the null hypothesis(H0: People who like to watch movies socially enjoy 'The Wolf of Wall Street(2013)' less than those who prefer to watch them alone.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9436657996253056\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "data = pd.read_csv('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', skipinitialspace = True)\n",
    "titles = data_with_name.columns\n",
    "titles = titles[:400]\n",
    "wolf_of_wall_street = data['The Wolf of Wall Street (2013)'].to_numpy()\n",
    "socially_enjoy = data['Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)'].to_numpy()\n",
    "\n",
    "movies_socially = []\n",
    "movies_alone = []\n",
    "\n",
    "for i in range(0, len(socially_enjoy)):\n",
    "    if socially_enjoy[i] == 1 and not np.isnan(wolf_of_wall_street[i]):\n",
    "        movies_alone.append(wolf_of_wall_street[i])\n",
    "    elif socially_enjoy[i] == 0 and not np.isnan(wolf_of_wall_street[i]):\n",
    "        movies_socially.append(wolf_of_wall_street[i])\n",
    "        \n",
    "u1, p1 = stats.mannwhitneyu(movies_socially, movies_alone, alternative = 'greater')\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. What proportion of movies exhibit such a \"social watching\" effect?\n",
    "\n",
    "Test: Mann Whitney U test\n",
    "\n",
    "- Reason for choosing this test\n",
    "\n",
    " Firstly, this movie rating data cannot be reduced to sample means considering the characteristics of movie rating score. For exmaple, difference in rating 3 and 4, and difference in rating 4 and 5 is not the same though numerically the difference is the same(1 point). This is because to be closer to 5 requires much better quality than closer to 4, because 5 is the perfect score.\n",
    " Next, the data is not categorical and it can be ordered from 0 to 4. In addition, there are some datas which is decimals such as 3.5 and 1.5, which means the data is continuous and cannot be separated into categories.\n",
    " Furthermore, the movie ratings should be divided into 2 groups which are viewers who like to watch movies socially and viewers who prefer to watch them alone. Finally, we will compare median value of the movie ratings, so Mann Whitney U test is proper test method.\n",
    "\n",
    "\n",
    "- How to do the test \\\n",
    "1) For each movie ratings, divide rates into 2 groups(viewers who like to watch movies socially and viewers who prefer to watch them alone)\\\n",
    "   (for the NaN value, discard it.)\\\n",
    "2) Run Mann Whitney U test for each movie and get p-value \\\n",
    "   (Since we are testing \"difference\" which means the same or not, use 'two-sided' option).\\\n",
    "\n",
    "    Ha : movies are rated differently by viewers who like to watch movies socially and viewers who prefer to watch them alone \\\n",
    "    H0 : movies are rated same by viewers who like to watch movies socially and viewers who prefer to watch them alone \\\n",
    "3) If p-value is smaller than significance level(0.005), count that movie\\\n",
    "    -> Reject Null Hypothesis(H0 : movies are rated same by viewers who like to watch movies socially and viewers who prefer to watch them alone)\\\n",
    "4) get the ratio with count\n",
    "\n",
    "\n",
    "- Test Result : 0.0175 \\\n",
    ": 10 movies out of 400 movies are rated differently by viewers with siblings group and viewers without siblings group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8\n",
    "data = pd.read_csv('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', skipinitialspace = True)\n",
    "titles = data_with_name.columns\n",
    "titles = titles[:400]\n",
    "socially_enjoy = data['Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)'].to_numpy()\n",
    "\n",
    "count = 0\n",
    "for title in titles:\n",
    "    movie_rating = data[title]\n",
    "    \n",
    "    movies_socially = []\n",
    "    movies_alone = []\n",
    "    \n",
    "    for i in range(0, len(socially_enjoy)):\n",
    "        if socially_enjoy[i] == 1 and not np.isnan(movie_rating[i]):\n",
    "            movies_alone.append(movie_rating[i])\n",
    "        elif socially_enjoy[i] == 0 and not np.isnan(movie_rating[i]):\n",
    "            movies_socially.append(movie_rating[i])\n",
    "    \n",
    "    u1, p1 = stats.mannwhitneyu(movies_socially, movies_alone) # alternative = two-sided\n",
    "    \n",
    "    if p1 < 0.005:\n",
    "        count += 1\n",
    "\n",
    "print(count)\n",
    "count / 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Is the ratings distribution of 'Home Alone(1990)' different than that of 'Finding Nemo(2003)'?\n",
    "\n",
    "Test: Kolmogorov-Smirnov(KS) test\n",
    "\n",
    "- Reason for choosing this test\n",
    "\n",
    " Firstly, this movie rating data cannot be reduced to sample means considering the characteristics of movie rating score. For exmaple, difference in rating 3 and 4, and difference in rating 4 and 5 is not the same though numerically the difference is just 1 point. This is because to be closer to 5 requires much better quality than closer to 4, because 5 is the perfect score.\n",
    " Next, the data is not categorical and it can be ordered from 0 to 4. In addition, there are some datas which is decimals such as 3.5 and 1.5, which means the data is continuous and cannot be separated into categories.\n",
    " Furthermore, the data should be divided into 2 groups which are ratings distribution of 'Home Alone(1990)' and that of 'Finding Nemo(2003)'. Since we should compare ratings distribution as mentioned in the problem, we should use KS test. \n",
    "\n",
    "\n",
    "- How to do the test \\\n",
    "1) For the movie 'Home Alone(1990)' and 'Finding Nemo(2003)', discard NaN value (element-wise) \\\n",
    "2) Run Kolmogorov-Smirnov(KS) test with ratings distribution for the movie 'Home Alone(1990)' and 'Finding Nemo(2003)'.\n",
    "\n",
    "\n",
    "- Test Result\n",
    "\n",
    " Ha: The ratings distribution of 'Home Alone(1990)' different than that of 'Finding Nemo(2003)'. \\\n",
    " H0: The ratings distribution of 'Home Alone(1990)' and that of 'Finding Nemo(2003)' are same. \\\n",
    "\n",
    " Based on the test, p-value is 6.379381467525036e-10 which is smaller than significance level(0.005).\n",
    " Accordingly, reject the null hypothesis(H0: The ratings distribution of 'Home Alone(1990)' and that of 'Finding Nemo(2003)' are same.), and the ratings distribution of 'Home Alone(1990)' different than that of 'Finding Nemo(2003)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.15269080020897632, pvalue=6.379381467525036e-10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9\n",
    "data = pd.read_csv('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', skipinitialspace = True)\n",
    "ha = data['Home Alone (1990)'].to_numpy()\n",
    "fn = data['Finding Nemo (2003)'].to_numpy()\n",
    "\n",
    "len(ha[~np.isnan(ha)])\n",
    "len(fn[~np.isnan(fn)])\n",
    "\n",
    "haa = ha[~np.isnan(ha)]\n",
    "fnn = fn[~np.isnan(fn)]\n",
    "\n",
    "stats.ks_2samp(haa, fnn) # default: two-sided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. There are ratings on movies from several franchises(['Star Wars', 'Harry Potter', 'The Matrix', 'Indiana Jones', 'Jurassic Park', 'Pirates of the Caribbean', 'Toy Story', 'Batman' ]) in this dataset. How many of these are of inconsistent quality, as experienced by viewers? [Hint: You can use the keywords in quotation marks featured in this question to identify the movies that are part of each franchise]\n",
    "\n",
    "Test: Kruskal-Wallis test\n",
    "\n",
    "- Reason for choosing this test\n",
    "\n",
    " Firstly, this movie rating data cannot be reduced to sample means considering the characteristics of movie rating score. For exmaple, difference in rating 3 and 4, and difference in rating 4 and 5 is not the same though numerically the difference is the same(1 point). This is because to be closer to 5 requires much better quality than closer to 4, because 5 is the perfect score.\n",
    " Next, the data is not categorical and it can be ordered from 0 to 4. In addition, there are some datas which is decimals such as 3.5 and 1.5, which means the data is continuous and cannot be separated into categories.\n",
    " Furthermore, the movies are divided into more than 3 groups which are movies ratings of each series(the number of series are more than 3 for above mentioned franchises).\n",
    "\n",
    "\n",
    "- How to do the test \\\n",
    "1) Get series data \\\n",
    "2) Drop the row that has NaN (The purpose of this experiment is to compare how these series has inconsistent quality, so the viewer who only watch all the series can only rate correctly.)\n",
    "3) Run Kruskal-Wallis test with movie ratings of each series\n",
    "\n",
    "\n",
    "- Test Result\n",
    "    | | movie  | p-value    | \n",
    "|---:|:-------------|:-----------|\n",
    "| 1 | Star Wars  | 6.940162236984522e-40       | \n",
    "| 2 | Harry Potter  | 0.11790622831256074    | \n",
    "| 3 | The Matrix  | 1.7537323830838066e-09    | \n",
    "| 4 | Indiana Jones  | 1.020118354785894e-11    | \n",
    "| 5 | Jurassic Park  | 1.8492328391686058e-11    | \n",
    "| 6 | Pirates of the Caribbean | 0.035792727694248905    | \n",
    "| 7 | Toy Story  | 7.902234665149812e-06    | \n",
    "| 8 | Batman  | 4.1380499020034183e-19    | \n",
    "\n",
    "\n",
    " Ha: Viewers experienced inconsistent quality in franchise \\\n",
    " H0: Viewers experienced consistent quality in franchise \n",
    "\n",
    " For the series that has p-value smaller than significance level(0.005), the series is of inconsistent quality as experienced by viewers. Accordingly, Star Wars, The Matrix, Indiana Jones, Jurssic Park, Toy Story, and Batman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=193.51026675400544, pvalue=6.940162236984522e-40)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10\n",
    "data = pd.read_csv('/Users/yjeonlee/Desktop/[DS-GA-1001]Intro to Data Science/Project1/movieReplicationSet.csv', skipinitialspace = True)\n",
    "franchises = ['Star Wars', 'Harry Potter', 'The Matrix', 'Indiana Jones', 'Jurassic Park', 'Pirates of the Caribbean', 'Toy Stroy', 'Batman']\n",
    "\n",
    "title = 'Star Wars'\n",
    "series = data.loc[:, data.columns.str.contains(title)]\n",
    "#num_row, num_col = series.shape\n",
    "#num_col\n",
    "\n",
    "dropped = series.dropna()\n",
    "splitted = []\n",
    "for dropped_movie in dropped:\n",
    "    dropped_np = dropped[dropped_movie].to_numpy()\n",
    "    splitted.append(dropped_np)\n",
    "    \n",
    "stats.kruskal(splitted[0], splitted[1], splitted[2], splitted[3], splitted[4], splitted[5])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=5.8739552218536755, pvalue=0.11790622831256074)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Harry Potter'\n",
    "hp_series = data.loc[:, data.columns.str.contains(title)]\n",
    "#num_row, num_col = series.shape\n",
    "#num_col\n",
    "\n",
    "dropped = hp_series.dropna()\n",
    "splitted = []\n",
    "for dropped_movie in dropped:\n",
    "    dropped_np = dropped[dropped_movie].to_numpy()\n",
    "    splitted.append(dropped_np)\n",
    "    \n",
    "#print(len(splitted))\n",
    "    \n",
    "stats.kruskal(splitted[0], splitted[1], splitted[2], splitted[3])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=40.32303905969196, pvalue=1.7537323830838066e-09)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'The Matrix'\n",
    "matrix_series = data.loc[:, data.columns.str.contains(title)]\n",
    "#num_row, num_col = series.shape\n",
    "#num_col\n",
    "\n",
    "dropped = matrix_series.dropna()\n",
    "splitted = []\n",
    "for dropped_movie in dropped:\n",
    "    dropped_np = dropped[dropped_movie].to_numpy()\n",
    "    splitted.append(dropped_np)\n",
    "    \n",
    "#print(len(splitted))\n",
    "    \n",
    "stats.kruskal(splitted[0], splitted[1], splitted[2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=54.19395477406098, pvalue=1.020118354785894e-11)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Indiana Jones'\n",
    "indiana_jones_series = data.loc[:, data.columns.str.contains(title)]\n",
    "#num_row, num_col = series.shape\n",
    "#num_col\n",
    "\n",
    "dropped = indiana_jones_series.dropna()\n",
    "splitted = []\n",
    "for dropped_movie in dropped:\n",
    "    dropped_np = dropped[dropped_movie].to_numpy()\n",
    "    splitted.append(dropped_np)\n",
    "    \n",
    "#print(len(splitted))\n",
    "    \n",
    "stats.kruskal(splitted[0], splitted[1], splitted[2], splitted[3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=49.42733030275783, pvalue=1.8492328391686058e-11)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Jurassic Park'\n",
    "jurassic_park_series = data.loc[:, data.columns.str.contains(title)]\n",
    "#num_row, num_col = series.shape\n",
    "#num_col\n",
    "\n",
    "dropped = jurassic_park_series.dropna()\n",
    "splitted = []\n",
    "for dropped_movie in dropped:\n",
    "    dropped_np = dropped[dropped_movie].to_numpy()\n",
    "    splitted.append(dropped_np)\n",
    "    \n",
    "#print(len(splitted))\n",
    "    \n",
    "stats.kruskal(splitted[0], splitted[1], splitted[2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=6.660021086485515, pvalue=0.035792727694248905)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Pirates of the Caribbean'\n",
    "pirates_of_the_caribbean_series = data.loc[:, data.columns.str.contains(title)]\n",
    "#num_row, num_col = series.shape\n",
    "#num_col\n",
    "\n",
    "dropped = pirates_of_the_caribbean_series.dropna()\n",
    "splitted = []\n",
    "for dropped_movie in dropped:\n",
    "    dropped_np = dropped[dropped_movie].to_numpy()\n",
    "    splitted.append(dropped_np)\n",
    "    \n",
    "#print(len(splitted))\n",
    "    \n",
    "stats.kruskal(splitted[0], splitted[1], splitted[2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=23.496729938969775, pvalue=7.902234665149812e-06)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Toy Story'\n",
    "toy_story_series = data.loc[:, data.columns.str.contains(title)]\n",
    "#num_row, num_col = series.shape\n",
    "#num_col\n",
    "\n",
    "dropped = toy_story_series.dropna()\n",
    "splitted = []\n",
    "for dropped_movie in dropped:\n",
    "    dropped_np = dropped[dropped_movie].to_numpy()\n",
    "    splitted.append(dropped_np)\n",
    "    \n",
    "#print(len(splitted))\n",
    "    \n",
    "stats.kruskal(splitted[0], splitted[1], splitted[2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=84.65778425637279, pvalue=4.1380499020034183e-19)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Batman'\n",
    "batman_series = data.loc[:, data.columns.str.contains(title)]\n",
    "#num_row, num_col = series.shape\n",
    "#num_col\n",
    "\n",
    "dropped = batman_series.dropna()\n",
    "splitted = []\n",
    "for dropped_movie in dropped:\n",
    "    dropped_np = dropped[dropped_movie].to_numpy()\n",
    "    splitted.append(dropped_np)\n",
    "    \n",
    "#print(len(splitted))\n",
    "    \n",
    "stats.kruskal(splitted[0], splitted[1], splitted[2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
